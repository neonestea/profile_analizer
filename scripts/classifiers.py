# -*- coding: utf-8 -*-
"""classifiers.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jaX4oajpoT7K_92T5kMB8_BSkDpifgIX
"""

import numpy as np
 import re
 import nltk
 nltk.download('stopwords')
 import pickle
 from nltk.corpus import stopwords

import pandas as pd

df = pd.read_csv('preprocessed_neur (1).csv', delimiter=';')

df_texts = df[['full_texts']]

"""Bag of words"""

X = df_texts.values

#from sklearn.feature_extraction.text import CountVectorizer
#vectorizer = CountVectorizer(max_features=1500, min_df=5, max_df=0.7)
#X = vectorizer.fit_transform(X.ravel())

"""Tf-idf"""

#from sklearn.feature_extraction.text import TfidfTransformer
#tfidfconverter = TfidfTransformer()
#X = tfidfconverter.fit_transform(X).toarray()

"""Без мешка слов"""

from sklearn.feature_extraction.text import TfidfVectorizer
tfidfconverter = TfidfVectorizer(max_features=1500, min_df=5, max_df=0.7)
X = tfidfconverter.fit_transform(X.ravel()).toarray()

import pickle
#pickle.dump(vectorizer, open("cons_count_vectorizer.pickle", "wb"))
pickle.dump(tfidfconverter, open("agree_tf_idf.pickle", "wb"))
#vectorizer = pickle.load(open("cons_count_vectorizer.pickle", "rb"))
#tfidfconverter = pickle.load(open("cons_tf_idf.pickle", "rb"))

tf_idf_df = pd.DataFrame(X)

tf_idf_df.shape

new_df = df.join(tf_idf_df)

new_df = new_df.drop('full_texts', axis = 1)

new_df = new_df.sample(frac=1)

new_df = new_df.drop('Unnamed: 0', axis = 1)

#new_df_for_catboost = new_df

!pip install category_encoders

from category_encoders.hashing import HashingEncoder

y_df = new_df[['label']]

x_df = new_df.drop('label', axis = 1)

y = y_df.values

X = x_df.values



#X_for_catboost = X

encoder = HashingEncoder()
countries = encoder.fit_transform(x_df['country'])
countries = countries.rename(columns={'col_0': 'country0', 'col_1': 'country1', 'col_2': 'country2', 'col_3': 'country3', 'col_4': 'country4',
                        'col_5': 'country5', 'col_6': 'country6', 'col_7': 'country7'})

import pickle
pickle.dump(encoder, open("neur_country_encoder.pickle", "wb"))
#encoder = pickle.load(open("cons_country_encoder.pickle", "rb"))

city = encoder.fit_transform(x_df['city'])
city = city.rename(columns={'col_0': 'city0', 'col_1': 'city1', 'col_2': 'city2', 'col_3': 'city3', 'col_4': 'city4',
                        'col_5': 'city5', 'col_6': 'city6', 'col_7': 'city7'})

import pickle
pickle.dump(encoder, open("neur_city_encoder.pickle", "wb"))
#encoder = pickle.load(open("cons_country_encoder.pickle", "rb"))

university_name = encoder.fit_transform(x_df['university_name'])
university_name = university_name.rename(columns={'col_0': 'university_name0', 'col_1': 'university_name1', 'col_2': 'university_name2', 'col_3': 'university_name3', 'col_4': 'university_name4',
                        'col_5': 'university_name5', 'col_6': 'university_name6', 'col_7': 'university_name7'})

import pickle
pickle.dump(encoder, open("neur_university_name_encoder.pickle", "wb"))
#encoder = pickle.load(open("cons_country_encoder.pickle", "rb"))

faculty = encoder.fit_transform(x_df['faculty'])
faculty = faculty.rename(columns={'col_0': 'faculty0', 'col_1': 'faculty1', 'col_2': 'faculty2', 'col_3': 'faculty3', 'col_4': 'faculty4',
                        'col_5': 'faculty5', 'col_6': 'faculty6', 'col_7': 'faculty7'})

import pickle
pickle.dump(encoder, open("neur_faculty_encoder.pickle", "wb"))
#encoder = pickle.load(open("cons_country_encoder.pickle", "rb"))

home_town = encoder.fit_transform(x_df['home_town'])
home_town = home_town.rename(columns={'col_0': 'home_town0', 'col_1': 'home_town1', 'col_2': 'home_town2', 'col_3': 'home_town3', 'col_4': 'home_town4',
                        'col_5': 'home_town5', 'col_6': 'home_town6', 'col_7': 'home_town7'})



import pickle
pickle.dump(encoder, open("neur_home_town_encoder.pickle", "wb"))
#encoder = pickle.load(open("cons_country_encoder.pickle", "rb"))

tmp_df = countries.join(city)
tmp_df = tmp_df.join(university_name)
tmp_df = tmp_df.join(faculty)
tmp_df = tmp_df.join(home_town)

x_df = tmp_df.join(x_df)

x_df = x_df.drop('country', axis = 1)
x_df = x_df.drop('city', axis = 1)
x_df = x_df.drop('home_town', axis = 1)
x_df = x_df.drop('faculty', axis = 1)
x_df = x_df.drop('university_name', axis = 1)

X = x_df.values

#from sklearn.preprocessing import StandardScaler

#scaler = StandardScaler()
#X_norm = scaler.fit_transform(X)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

#X_norm_train, X_norm_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=42)

#X_cb_train, X_cb_test, y_train, y_test = train_test_split(X_for_catboost, y, test_size=0.3, random_state=42)

"""#Neural Network"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense
from keras import optimizers

hidden_units=100
learning_rate=0.01
hidden_layer_act='tanh'
output_layer_act='sigmoid'
no_epochs=500

model = Sequential()

model.add(Dense(hidden_units, input_dim=X_train.shape[1], activation=hidden_layer_act))
model.add(Dense(hidden_units, activation='ReLU'))
model.add(Dense(hidden_units, activation=hidden_layer_act))
model.add(Dense(1, activation=output_layer_act))

sgd=optimizers.SGD(lr=learning_rate)
model.compile(loss='binary_crossentropy',optimizer=sgd, metrics=['acc'])

model.fit(X_train, y_train, epochs=no_epochs, batch_size=len(X_train),  verbose=2)

predictions = model.predict(X_test)

rounded = [int(round(x[0])) for x in predictions]

print(confusion_matrix(y_test,rounded))
print(classification_report(y_test,rounded))
print(accuracy_score(y_test, rounded))
print(roc_auc_score(y_test, rounded))
#scores = cross_val_score(classifier, X, y, cv=10)
#print(scores)
#print(scores.mean())

"""Random Forest"""

from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.metrics import roc_auc_score

from sklearn.model_selection import cross_val_score

from sklearn.ensemble import RandomForestClassifier

classifier = RandomForestClassifier()
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
print(roc_auc_score(y_test, y_pred))
scores = cross_val_score(classifier, X, y, cv=10)
print(scores)
print(scores.mean())

import numpy as np

np.argmax(classifier.feature_importances_)

"""SGDClassifier"""

from sklearn.linear_model import SGDClassifier

classifier = SGDClassifier()
classifier.fit(X_norm_train, y_train)
y_pred = classifier.predict(X_norm_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
print(roc_auc_score(y_test, y_pred))
scores = cross_val_score(classifier, X, y, cv=10)
print(scores.mean())

"""DecisionTreeClassifier"""

from sklearn.tree import DecisionTreeClassifier

classifier = DecisionTreeClassifier()
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
print(roc_auc_score(y_test, y_pred))
scores = cross_val_score(classifier, X, y, cv=10)
print(scores.mean())

"""Catboost"""

!pip install catboost

from catboost import CatBoostClassifier

cat_features = [0, 1, 3, 4, 5]

classifier = CatBoostClassifier(n_estimators=1000, depth=10)
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
print(roc_auc_score(y_test, y_pred))
#scores = cross_val_score(classifier, X, y, cv=10)
#print(scores.mean())

import pickle
pickle.dump(classifier, open("agree_classifier.pickle", "wb"))
#encoder = pickle.load(open("cons_country_encoder.pickle", "rb"))

"""AdaBoostClassifier"""

from sklearn.ensemble import AdaBoostClassifier

classifier = AdaBoostClassifier()
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
print(roc_auc_score(y_test, y_pred))
scores = cross_val_score(classifier, X, y, cv=10)
print(scores.mean())

"""BaggingClassifier"""

from sklearn.ensemble import BaggingClassifier

classifier = BaggingClassifier()
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
print(roc_auc_score(y_test, y_pred))
scores = cross_val_score(classifier, X, y, cv=10)
print(scores.mean())

"""LogisticRegression"""

from sklearn.linear_model import LogisticRegression

classifier = LogisticRegression()
classifier.fit(X_norm_train, y_train)
y_pred = classifier.predict(X_norm_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
print(roc_auc_score(y_test, y_pred))
scores = cross_val_score(classifier, X, y, cv=10)
print(scores.mean())

"""KNeighborsClassifier"""

from sklearn.neighbors import KNeighborsClassifier

classifier = KNeighborsClassifier()
classifier.fit(X_norm_train, y_train)
y_pred = classifier.predict(X_norm_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
print(roc_auc_score(y_test, y_pred))
scores = cross_val_score(classifier, X, y, cv=10)
print(scores.mean())

"""GradientBoostingClassifier"""

from sklearn.ensemble import GradientBoostingClassifier

classifier = GradientBoostingClassifier(max_depth=10, n_estimators = 1000)
classifier.fit(X_train, y_train)
y_pred = classifier.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
print(roc_auc_score(y_test, y_pred))
#scores = cross_val_score(classifier, X, y, cv=10)
#print(scores.mean())

import pickle
pickle.dump(classifier, open("neur_classifier.pickle", "wb"))
#encoder = pickle.load(open("cons_country_encoder.pickle", "rb"))

"""SVM"""

from sklearn import svm

classifier = svm.SVC()
classifier.fit(X_norm_train, y_train)
y_pred = classifier.predict(X_norm_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test, y_pred))
print(roc_auc_score(y_test, y_pred))
scores = cross_val_score(classifier, X, y, cv=10)
print(scores.mean())

ys = [0.81, 0.70, 0.85, 0.82, 0.87]
n_bins = 6

# import module
import matplotlib.pyplot as plt

plt.plot(['open', 'neur', 'extr', 'cons', 'agree'], ys)